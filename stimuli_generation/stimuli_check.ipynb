{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24453d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import natasha\n",
    "from scipy import  stats\n",
    "from collections import Counter\n",
    "import pymorphy2\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import itertools\n",
    "import json\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "tqdm.pandas()\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc58b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_base(text):\n",
    "    res = {'nsubj': '',\n",
    "           'root': '',\n",
    "          'dobj': ''}\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    doc.parse_syntax(syntax_parser) \n",
    "    tokens = {tok.id: tok for tok in doc.tokens}\n",
    "    ok = 0\n",
    "    for tok in doc.tokens:\n",
    "        if tok.rel == 'root':\n",
    "            res['root'] = tok.text\n",
    "            ok += tok.pos == 'VERB'\n",
    "        elif tok.rel == 'nsubj' and tokens[tok.head_id].rel == 'root':\n",
    "            res['nsubj'] = tok.text\n",
    "            ok += tok.pos == 'NOUN'\n",
    "        elif tok.rel == 'obj' and tokens[tok.head_id].rel == 'root':\n",
    "            res['dobj'] = tok.text\n",
    "            ok += tok.pos == 'NOUN'        \n",
    "    return (' '.join(res.values()).strip().capitalize(), ok == 3)\n",
    "\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a28d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noun = pd.read_excel('Neurointerfaces_ incongruent sentences.xlsx', 'all_NOUN')\n",
    "df_noun['table_name'] = 'all_NOUN'\n",
    "df_verb = pd.read_excel('Neurointerfaces_ incongruent sentences.xlsx', 'all_VERB')\n",
    "df_verb['table_name'] = 'all_VERB'\n",
    "df_adj = pd.read_excel('Neurointerfaces_ incongruent sentences.xlsx', 'all_ADJ')\n",
    "df_adj['table_name'] = 'all_ADJ'\n",
    "df = pd.concat([df_noun, df_verb, df_adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base'] = df['congruent'].progress_apply(find_base)\n",
    "df[['base sent', 'criterion']] = pd.DataFrame(df.base.tolist(), index = df.index)\n",
    "df['criterion'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475feecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df[df['criterion']].to_excel('stimuli_AZH.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cba3e",
   "metadata": {},
   "source": [
    "# Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d29bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_struct(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    doc.parse_syntax(syntax_parser) \n",
    "    tokens = {tok.id: tok for tok in doc.tokens}\n",
    "    ok = 0\n",
    "    if (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'NOUN' and \n",
    "        len(doc.tokens) == 3):\n",
    "        return 'Subject - Verb - Object'\n",
    "    elif len(doc.tokens) == 3:\n",
    "        return 'check me'\n",
    "    elif (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'NOUN' and \n",
    "        doc.tokens[3].pos == 'NOUN' and \n",
    "        doc.tokens[3].feats['Case'] == 'Gen' and \n",
    "        len(doc.tokens) == 4):\n",
    "        return 'Subject - Verb - Object - Gen'\n",
    "    elif (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'ADJ' and \n",
    "        doc.tokens[3].pos == 'NOUN' and \n",
    "        len(doc.tokens) == 4):\n",
    "        return 'Subject - Verb - Adj - Obj'\n",
    "    elif (doc.tokens[0].pos == 'NOUN' and \n",
    "        doc.tokens[1].pos == 'VERB' and \n",
    "        doc.tokens[2].pos == 'NOUN' and \n",
    "        doc.tokens[3].pos == 'ADP' and \n",
    "        doc.tokens[4].pos == 'NOUN' and \n",
    "        len(doc.tokens) == 5):\n",
    "        return 'Subject - Verb - Obj - PP'\n",
    "    \n",
    "def count_syllables(word):\n",
    "    if not isinstance(word, str):\n",
    "        return\n",
    "    counter = 0\n",
    "    vowels = 'аеиюэоыуея'\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "def normalize(word):\n",
    "    if not isinstance(word, str):\n",
    "        return\n",
    "    return morph.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0687050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table(df: pd.DataFrame, column: str, df_name=None, sheet=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function to find sentence syntactic structure,\n",
    "    words' length in syllables and word frequencies\n",
    "    :param df: pd.DataFrame\n",
    "    :param df_name: path to df\n",
    "    :param sheet: sheet_name\n",
    "    :param column: column name\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    if df_name is not None:\n",
    "        df = pd.read_excel(df_name, sheet_name=sheet)\n",
    "    df['length'] = df[column].apply(lambda x: len(x.split(' ')))\n",
    "    df['Structure'] = df[column].progress_apply(find_struct)\n",
    "    df['words'] = df[column].apply(lambda x: x.split())\n",
    "\n",
    "    subjects = []\n",
    "    verbs = []\n",
    "    objectives = []\n",
    "    genitives = []\n",
    "    adjectives = []\n",
    "    prepositions = []\n",
    "    objectives2 = []\n",
    "\n",
    "    for sent, struct in zip(df['words'], df['Structure']):\n",
    "        subjects.append(sent[0].lower())\n",
    "        verbs.append(sent[1])\n",
    "        obj = sent[2] if struct != 'Subject - Verb - Adj - Object' else sent[3]\n",
    "        objectives.append(obj)\n",
    "        gen = sent[3] if struct == 'Subject - Verb - Object - Gen' else None\n",
    "        genitives.append(gen)\n",
    "        adj = sent[2] if struct == 'Subject - Verb - Adj - Object' else None\n",
    "        adjectives.append(adj)\n",
    "        prep = sent[3] if struct == 'Subject - Verb - Object - PP' else None\n",
    "        prepositions.append(prep)\n",
    "        if struct == 'Subject - Verb - Object - PP':\n",
    "            obj2 = sent[4] \n",
    "        else:\n",
    "            obj2 = None\n",
    "        objectives2.append(obj2)\n",
    "\n",
    "\n",
    "    df['Subject'] = subjects\n",
    "    df['Verb'] = verbs\n",
    "    df['Object'] = objectives\n",
    "    df['Gen'] = genitives\n",
    "    df['Adj'] = adjectives\n",
    "    df['Preposition'] = prepositions\n",
    "    df['Object 2'] = objectives2\n",
    "\n",
    "    for column in ['Subject', 'Verb',\n",
    "                   'Object', 'Gen', 'Adj',\n",
    "                   'Preposition', 'Object 2']:\n",
    "        df[f'{column} length'] = df[column].map(count_syllables)\n",
    "        df[f'{column} lemma'] = df[column].map(lambda x: normalize(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5508e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ipm_in_dict(df):\n",
    "    frequency_noun = pd.read_excel('ruscorpora_content_noun.xlsx')\n",
    "    frequency_adj = pd.read_excel('ruscorpora_content_adj.xlsx')\n",
    "    frequency_verb = pd.read_excel('ruscorpora_content_verb.xlsx')\n",
    "\n",
    "    frequency_noun = frequency_noun.rename(columns={'ipm': 'ipm_noun'})\n",
    "    frequency_adj = frequency_adj.rename(columns={'ipm': 'ipm_adj'})\n",
    "    frequency_verb = frequency_verb.rename(columns={'ipm': 'ipm_verb'})\n",
    "\n",
    "    df = pd.merge(df, frequency_noun[['lex', 'ipm_noun']], how='left',\n",
    "                  left_on='Subject lemma', right_on='lex')\n",
    "    df = pd.merge(df, frequency_noun[['lex', 'ipm_noun']], how='left',\n",
    "                  left_on='Gen lemma', right_on='lex')\n",
    "    df = pd.merge(df, frequency_noun[['lex', 'ipm_noun']], how='left', \n",
    "                  left_on='Object lemma', right_on='lex')\n",
    "    df = pd.merge(df, frequency_noun[['lex', 'ipm_noun']], how='left', \n",
    "                  left_on='Object 2 lemma', right_on='lex')\n",
    "    df = pd.merge(df, frequency_verb[['lex', 'ipm_verb']], how='left', \n",
    "                  left_on='Verb lemma', right_on='lex')\n",
    "    df = pd.merge(df, frequency_adj[['lex', 'ipm_adj']], how='left', \n",
    "                  left_on='Adj lemma', right_on='lex')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8b7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ipm_in_ruscorpora(df, target_columns):    \n",
    "\n",
    "    def find_ipm(word, driver):\n",
    "        try:\n",
    "            driver.get(F'https://ruscorpora.ru/explore?req={word}')  \n",
    "            time.sleep(0.5)\n",
    "            driver.find_elements(By.CLASS_NAME, 'link--accent')[1].click()\n",
    "            time.sleep(0.5)\n",
    "            button = [button for button in driver.find_elements(By.TAG_NAME, 'button')\n",
    "                     if button.text == 'Частотность'][0]\n",
    "            button.click()\n",
    "            time.sleep(0.5)\n",
    "            return float(driver.find_element(By.XPATH, '/html/body/div[4]/main/div/div[3]/div[1]/div[1]/div[2]/div/table/tbody/tr/td[5]/span').text.replace(',', '.')) \n",
    "        except Exception as e:\n",
    "            print(e, word)\n",
    "            return \n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    for column in target_columns: \n",
    "        words += df[f'{column} lemma'].tolist()\n",
    "\n",
    "    words_ipm_dict = {w: find_ipm(w, driver) for w in tqdm(set(words))}\n",
    "\n",
    "    for col in ['Subject', 'Object', 'Object 2',\n",
    "                'Verb', 'Object', 'Gen', 'Adj',\n",
    "                'Object 2']:\n",
    "        df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
    "        df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
    "            lambda x: morph.parse(x)[0].tag.gender if isinstance(x, str) else None)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc894422",
   "metadata": {},
   "source": [
    "# Выбор контрольных стимулов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b41d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_excel('stimuli_versions\\stimuli_AZH.xlsx', sheet_name='stimuli')\n",
    "katya_df = pd.read_excel('stimuli_versions\\stimuli_new.xlsx', sheet_name='break_everything')\n",
    "result_df = pd.merge(katya_df, my_df, how='left', left_on='congruent', right_on='sent corrected' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad44ca3",
   "metadata": {},
   "source": [
    "## Объединение датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf5b3d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc570ba669742d7bcad7cea51128856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcc9c541bc048a0ae2070d81d7c7acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{col}'] = df[f'{col} lemma'].map(words_ipm_dict)\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\2988255427.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{col} gender'] = df[f'{col} lemma'].map(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congruent</th>\n",
       "      <th>sem_incongruent</th>\n",
       "      <th>position</th>\n",
       "      <th>gram_incongruent_CASE</th>\n",
       "      <th>gram_incongruent_NUMBER</th>\n",
       "      <th>sem_incongruent_CASE</th>\n",
       "      <th>sem_incongruent_NUMBER</th>\n",
       "      <th>sent corrected</th>\n",
       "      <th>selected</th>\n",
       "      <th>Structure</th>\n",
       "      <th>...</th>\n",
       "      <th>Adj gender</th>\n",
       "      <th>Preposition</th>\n",
       "      <th>Object 2</th>\n",
       "      <th>Preposition length</th>\n",
       "      <th>Preposition lemma</th>\n",
       "      <th>Object 2 length</th>\n",
       "      <th>Object 2 lemma</th>\n",
       "      <th>ipm_Object 2</th>\n",
       "      <th>Object 2 gender</th>\n",
       "      <th>Verb gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Полиция ведет поиски заявителя</td>\n",
       "      <td>Полиция ведет округа заявителя</td>\n",
       "      <td>2</td>\n",
       "      <td>Полиция ведет поискам заявителя</td>\n",
       "      <td>Полиция ведет поиск заявителя</td>\n",
       "      <td>Полиция ведет округ заявителя</td>\n",
       "      <td>Полиция ведет округов заявителя</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.04</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          congruent                 sem_incongruent  position  \\\n",
       "572  Полиция ведет поиски заявителя  Полиция ведет округа заявителя         2   \n",
       "\n",
       "               gram_incongruent_CASE        gram_incongruent_NUMBER  \\\n",
       "572  Полиция ведет поискам заявителя  Полиция ведет поиск заявителя   \n",
       "\n",
       "              sem_incongruent_CASE           sem_incongruent_NUMBER  \\\n",
       "572  Полиция ведет округ заявителя  Полиция ведет округов заявителя   \n",
       "\n",
       "    sent corrected  selected                      Structure  ...  Adj gender  \\\n",
       "572            NaN       NaN  Subject - Verb - Object - Gen  ...        None   \n",
       "\n",
       "    Preposition Object 2 Preposition length Preposition lemma Object 2 length  \\\n",
       "572        None     None               None              None            None   \n",
       "\n",
       "    Object 2 lemma  ipm_Object 2 Object 2 gender  Verb gender  \n",
       "572           None          0.04            None         None  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_processed = result_df[result_df['Structure'].notnull()]\n",
    "\n",
    "result_df_unprocessed = result_df[result_df['Structure'].isnull()].drop_duplicates(subset=['congruent'])\n",
    "df_processed = process_table(result_df_unprocessed, 'congruent')\n",
    "\n",
    "df_processed = df_processed[df_processed['Structure'].isin(['Subject - Verb - Object - Gen',\n",
    "                                               'Subject - Verb - Adj - Obj',\n",
    "                                               'Subject - Verb - Obj']\n",
    "                                               )]\n",
    "target_columns = ['Subject', 'Object','Verb', 'Gen', 'Adj']\n",
    "df_processed =  find_ipm_in_ruscorpora(df_processed, target_columns)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4846a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([df_processed, result_df_processed]).reset_index()\n",
    "\n",
    "result_df = result_df.dropna(subset=['sem_incongruent_CASE', 'sem_incongruent_NUMBER',\n",
    "                                    'gram_incongruent_NUMBER', 'gram_incongruent_CASE'],\n",
    "                            how='any')\n",
    "result_df = result_df.sort_values('congruent').reset_index()\n",
    "\n",
    "# Берем первый вариант сломанной семантики\n",
    "\n",
    "duplicates_first = [1]\n",
    "for idx in range(1, result_df.shape[0]):\n",
    "    if result_df['congruent'][idx-1] != result_df['congruent'][idx]:\n",
    "        duplicates_first.append(1)\n",
    "    else:\n",
    "        duplicates_first.append(0)\n",
    "result_df['duplicates_first']  = duplicates_first  \n",
    "result_df = result_df[result_df['duplicates_first'] == 1]\n",
    "result_df['sentence_id'] = list(range(result_df.shape[0]))\n",
    "target_columns = ['sentence_id', 'congruent', 'position', 'sem_incongruent', \n",
    "                  'gram_incongruent_CASE', 'gram_incongruent_NUMBER',\n",
    "                  'sem_incongruent_CASE', 'sem_incongruent_NUMBER',\n",
    "                  'Structure', 'length', 'words', \n",
    "                  'Subject', 'Verb', 'Object', 'Gen', 'Adj', \n",
    "                  'Subject length', 'Subject lemma', \n",
    "                  'Verb length', 'Verb lemma', \n",
    "                  'Object length', 'Object lemma', \n",
    "                  'Gen length', 'Gen lemma', \n",
    "                  'Adj length', 'Adj lemma', \n",
    "                  'ipm_Subject', 'ipm_Gen', 'ipm_Object', 'ipm_Verb', 'ipm_Adj', \n",
    "                  'Subject gender', 'Object gender', 'Gen gender', 'Adj gender']\n",
    "result_df = result_df.sort_values('congruent')[target_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f11eaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>congruent</th>\n",
       "      <th>position</th>\n",
       "      <th>sem_incongruent</th>\n",
       "      <th>gram_incongruent_CASE</th>\n",
       "      <th>gram_incongruent_NUMBER</th>\n",
       "      <th>sem_incongruent_CASE</th>\n",
       "      <th>sem_incongruent_NUMBER</th>\n",
       "      <th>Structure</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>ipm_Gen</th>\n",
       "      <th>ipm_Object</th>\n",
       "      <th>ipm_Verb</th>\n",
       "      <th>ipm_Adj</th>\n",
       "      <th>Subject gender</th>\n",
       "      <th>Object gender</th>\n",
       "      <th>Gen gender</th>\n",
       "      <th>Adj gender</th>\n",
       "      <th>task_type</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>3</td>\n",
       "      <td>Автобусы проходят массовую фортуну</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцией</td>\n",
       "      <td>Автобусы проходят массовую дезинфекции</td>\n",
       "      <td>Автобусы проходят массовую фортуной</td>\n",
       "      <td>Автобусы проходят массовую фортуны</td>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.63</td>\n",
       "      <td>181.770609</td>\n",
       "      <td>50.834561</td>\n",
       "      <td>masc</td>\n",
       "      <td>femn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Автомобиль получил технические повреждения</td>\n",
       "      <td>3</td>\n",
       "      <td>Автомобиль получил технические поколения</td>\n",
       "      <td>Автомобиль получил технические повреждение</td>\n",
       "      <td>Автомобиль получил технические повреждений</td>\n",
       "      <td>Автомобиль получил технические поколением</td>\n",
       "      <td>Автомобиль получил технические поколений</td>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.89</td>\n",
       "      <td>552.890944</td>\n",
       "      <td>73.606628</td>\n",
       "      <td>masc</td>\n",
       "      <td>neut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>masc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                   congruent  position  \\\n",
       "0            0      Автобусы проходят массовую дезинфекцию         3   \n",
       "1            1  Автомобиль получил технические повреждения         3   \n",
       "\n",
       "                            sem_incongruent  \\\n",
       "0        Автобусы проходят массовую фортуну   \n",
       "1  Автомобиль получил технические поколения   \n",
       "\n",
       "                        gram_incongruent_CASE  \\\n",
       "0     Автобусы проходят массовую дезинфекцией   \n",
       "1  Автомобиль получил технические повреждение   \n",
       "\n",
       "                      gram_incongruent_NUMBER  \\\n",
       "0      Автобусы проходят массовую дезинфекции   \n",
       "1  Автомобиль получил технические повреждений   \n",
       "\n",
       "                        sem_incongruent_CASE  \\\n",
       "0        Автобусы проходят массовую фортуной   \n",
       "1  Автомобиль получил технические поколением   \n",
       "\n",
       "                     sem_incongruent_NUMBER                      Structure  \\\n",
       "0        Автобусы проходят массовую фортуны  Subject - Verb - Adj - Object   \n",
       "1  Автомобиль получил технические поколений  Subject - Verb - Adj - Object   \n",
       "\n",
       "   length  ... ipm_Gen ipm_Object    ipm_Verb    ipm_Adj Subject gender  \\\n",
       "0     4.0  ...    0.02       1.63  181.770609  50.834561           masc   \n",
       "1     4.0  ...    0.02      14.89  552.890944  73.606628           masc   \n",
       "\n",
       "  Object gender  Gen gender Adj gender    task_type selected  \n",
       "0          femn         NaN       masc  to_evaluate        1  \n",
       "1          neut         NaN       masc          NaN        0  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected = pd.read_excel('stimuli_versions/stimuli_selected.xlsx')\n",
    "result_df = pd.merge(result_df, df_selected[['task_type', 'selected', 'congruent']],\n",
    "                     how='left', on='congruent')\n",
    "result_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83baecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel('stimuli_all.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5b3e9",
   "metadata": {},
   "source": [
    "## Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b70e62b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "Verb\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "Object\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Adj - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "('Subject - Verb - Object', 'Subject - Verb - Object - Gen')\n",
      "ipm True\n",
      "length True\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\3512255522.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'ipm_{item}'] = df[f'ipm_{item}'].dropna()\n"
     ]
    }
   ],
   "source": [
    "df = result_df\n",
    "df = df[(df['task_type'] == 'to_evaluate')]\n",
    "\n",
    "#next 5 lines to check distribution in after toloka evaluation\n",
    "# selected = pd.read_excel('toloka_selected.xlsx')\n",
    "# df = df[df['congruent'].isin(selected['sentence'].tolist())]\n",
    "\n",
    "# comp1 = mc.MultiComparison(dataframe[ValueColumn], dataframe[CategoricalColumn])\n",
    "# tbl, a1, a2 = comp1.allpairtest(stats.ttest_ind, method= \"bonf\")\n",
    "\n",
    "for item in ['Subject', 'Verb', 'Object']:\n",
    "    print(item)\n",
    "    df[f'ipm_{item}'] = df[f'ipm_{item}'].dropna()\n",
    "    for comb in itertools.combinations(df['Structure'].unique(), 2):\n",
    "        print(comb)\n",
    "        print('ipm', \n",
    "              stats.ttest_ind(df[df['Structure'] == comb[0]][f'ipm_{item}'].dropna().tolist(),\n",
    "                              df[df['Structure'] == comb[1]][f'ipm_{item}'].dropna().tolist()).pvalue > 0.05)\n",
    "        print('length', \n",
    "              stats.ttest_ind(df[df['Structure'] == comb[0]][f'{item} length'].dropna().tolist(),\n",
    "                              df[df['Structure'] == comb[1]][f'{item} length']).pvalue > 0.05)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5118a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject - Verb - Adj - Object    75\n",
       "Subject - Verb - Object          75\n",
       "Subject - Verb - Object - Gen    75\n",
       "Name: Structure, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Structure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f09c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638782979165149"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(df[df['Structure'] == 'Subject - Verb - Adj - Object'][f'ipm_Adj'].dropna().tolist(),\n",
    "                df[df['Structure'] == 'Subject - Verb - Object - Gen'][f'ipm_Gen'].dropna().tolist()).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "695196d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "Verb\n",
      "ipm True\n",
      "length True\n",
      "\n",
      "Object\n",
      "ipm True\n",
      "length True\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\3585805600.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[f'ipm_{item}'] = df1[f'ipm_{item}'].dropna()\n",
      "C:\\Users\\zhuravleva\\AppData\\Local\\Temp\\ipykernel_12852\\3585805600.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[f'ipm_{item}'] = df2[f'ipm_{item}'].dropna()\n"
     ]
    }
   ],
   "source": [
    "df1 = result_df[result_df['task_type'] == 'control']\n",
    "df2 = result_df[result_df['task_type'] == 'to_evaluate']\n",
    "\n",
    "# comp1 = mc.MultiComparison(dataframe[ValueColumn], dataframe[CategoricalColumn])\n",
    "# tbl, a1, a2 = comp1.allpairtest(stats.ttest_ind, method= \"bonf\")\n",
    "\n",
    "for item in ['Subject', 'Verb', 'Object']:\n",
    "    print(item)\n",
    "    df1[f'ipm_{item}'] = df1[f'ipm_{item}'].dropna()\n",
    "    df2[f'ipm_{item}'] = df2[f'ipm_{item}'].dropna()\n",
    "    print('ipm', \n",
    "              stats.ttest_ind(df1[f'ipm_{item}'].dropna().tolist(),\n",
    "                              df2[f'ipm_{item}'].dropna().tolist()).pvalue > 0.05)\n",
    "    print('length', \n",
    "              stats.ttest_ind(df1[f'{item} length'].dropna().tolist(),\n",
    "                              df2[f'{item} length']).pvalue > 0.05)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a87c6c",
   "metadata": {},
   "source": [
    "## Формирование выборки для толоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5defafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('stimuli_versions/stimuli_all.xlsx')\n",
    "# df = df[df['selected'] == 1].sort_values('task_type', ascending=False).reset_index()\n",
    "my_pull = []\n",
    "for idx, row in df.dropna(subset='task_type').iterrows():\n",
    "    my_pull.append({'sentence_id': row['sentence_id'],\n",
    "                    'sentence': row['congruent'], \n",
    "                    'target': 'no'})\n",
    "    my_pull.append({'sentence_id': row['sentence_id'],\n",
    "                    'sentence': row['sem_incongruent'], \n",
    "                    'target': 'semantics'})\n",
    "    my_pull.append({'sentence_id': row['sentence_id'],\n",
    "                    'sentence': row['gram_incongruent_CASE'], \n",
    "                    'target': 'grammar'})\n",
    "    my_pull.append({'sentence_id': row['sentence_id'],\n",
    "                    'sentence': row['sem_incongruent_CASE'], \n",
    "                    'target': 'semantics_grammar'})\n",
    "my_pull = pd.DataFrame(my_pull)     \n",
    "\n",
    "# Для второй итерации\n",
    "# my_pull = my_pull[my_pull['error_type'].isin(['gram_incongruent_CASE', 'sem_incongruent_CASE'])]\n",
    "# my_pull2 = my_pull[['sentence']].rename(columns={'sentence': 'INPUT:comment'})\n",
    "# my_pull2.to_excel('toloka_iter2_case_only.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed65cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel('stimuli_versions/stimuli_edited.xlsx')\n",
    "new_stimuli = pd.concat([my_pull, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252784db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>target</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>semantics_grammar</td>\n",
       "      <td>Адвокат обжаловал воспоминанием властей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>grammar</td>\n",
       "      <td>Администратор нажала кнопке сигнализации</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id             target                                  sentence\n",
       "0            4  semantics_grammar   Адвокат обжаловал воспоминанием властей\n",
       "1            6            grammar  Администратор нажала кнопке сигнализации"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a72afbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую фортуну</td>\n",
       "      <td>semantics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                sentence     target\n",
       "0            0  Автобусы проходят массовую дезинфекцию         no\n",
       "1            0      Автобусы проходят массовую фортуну  semantics"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pull.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de391d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую фортуну</td>\n",
       "      <td>semantics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                sentence     target\n",
       "0            0  Автобусы проходят массовую дезинфекцию         no\n",
       "1            0      Автобусы проходят массовую фортуну  semantics"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stimuli.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be33333",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stimuli.to_excel('stimuli_versions/toloka.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6d0ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили орудия</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили посещения</td>\n",
       "      <td>semantics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили орудию</td>\n",
       "      <td>grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили посещение</td>\n",
       "      <td>semantics_grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили телевидения</td>\n",
       "      <td>semantics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили телевидению</td>\n",
       "      <td>semantics_grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили знакомстве</td>\n",
       "      <td>semantics_grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>8</td>\n",
       "      <td>Артиллеристы подготовили знакомства</td>\n",
       "      <td>semantics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id                              sentence             target\n",
       "24             8       Артиллеристы подготовили орудия                 no\n",
       "25             8    Артиллеристы подготовили посещения          semantics\n",
       "26             8       Артиллеристы подготовили орудию            grammar\n",
       "27             8    Артиллеристы подготовили посещение  semantics_grammar\n",
       "97             8  Артиллеристы подготовили телевидения          semantics\n",
       "98             8  Артиллеристы подготовили телевидению  semantics_grammar\n",
       "262            8   Артиллеристы подготовили знакомстве  semantics_grammar\n",
       "263            8   Артиллеристы подготовили знакомства          semantics"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stimuli[new_stimuli['sentence_id'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b45176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('FINAL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12136dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>congruent</th>\n",
       "      <th>target</th>\n",
       "      <th>Structure</th>\n",
       "      <th>percent</th>\n",
       "      <th>position</th>\n",
       "      <th>semantics_grammar</th>\n",
       "      <th>semantics</th>\n",
       "      <th>grammar</th>\n",
       "      <th>...</th>\n",
       "      <th>Subject gender</th>\n",
       "      <th>Object gender</th>\n",
       "      <th>Gen gender</th>\n",
       "      <th>Adj gender</th>\n",
       "      <th>task_type</th>\n",
       "      <th>target==eval</th>\n",
       "      <th>percent&gt;75&amp;evalCorrect</th>\n",
       "      <th>percent&gt;75&amp;evalCorrect&amp;normEvalCorrect&amp;SemEvalCorrect</th>\n",
       "      <th>percent&gt;75&amp;evalCorrect&amp;normEvalCorrect&amp;GramEvalCorrect</th>\n",
       "      <th>percent&gt;75&amp;evalCorrect&amp;normEvalCorrect&amp;SemGramEvalCorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцией</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>grammar</td>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>masc</td>\n",
       "      <td>femn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>Автобусы проходят массовую дезинфекцию</td>\n",
       "      <td>no</td>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>masc</td>\n",
       "      <td>femn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>masc</td>\n",
       "      <td>to_evaluate</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                 sentence  \\\n",
       "0            0  Автобусы проходят массовую дезинфекцией   \n",
       "1            0   Автобусы проходят массовую дезинфекцию   \n",
       "\n",
       "                                congruent   target  \\\n",
       "0  Автобусы проходят массовую дезинфекцию  grammar   \n",
       "1  Автобусы проходят массовую дезинфекцию       no   \n",
       "\n",
       "                       Structure   percent  position  semantics_grammar  \\\n",
       "0  Subject - Verb - Adj - Object  1.000000         3                NaN   \n",
       "1  Subject - Verb - Adj - Object  0.833333         3                NaN   \n",
       "\n",
       "   semantics  grammar  ...  Subject gender  Object gender Gen gender  \\\n",
       "0        NaN      1.0  ...            masc           femn        NaN   \n",
       "1   0.166667      NaN  ...            masc           femn        NaN   \n",
       "\n",
       "   Adj gender    task_type target==eval percent>75&evalCorrect  \\\n",
       "0        masc  to_evaluate         True                   True   \n",
       "1        masc  to_evaluate         True                   True   \n",
       "\n",
       "  percent>75&evalCorrect&normEvalCorrect&SemEvalCorrect  \\\n",
       "0                                              False      \n",
       "1                                              False      \n",
       "\n",
       "  percent>75&evalCorrect&normEvalCorrect&GramEvalCorrect  \\\n",
       "0                                              False       \n",
       "1                                              False       \n",
       "\n",
       "  percent>75&evalCorrect&normEvalCorrect&SemGramEvalCorrect  \n",
       "0                                              False         \n",
       "1                                              False         \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439e272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_table = pd.DataFrame(df['sentence'].apply(lambda x:x.split()).tolist())\n",
    "exp_table['sent_id'] = df['sentence_id']\n",
    "exp_table['target'] = df['target']\n",
    "exp_table = exp_table.rename(columns={0: 'w1', 1: 'w2', 2: 'w3', 3:'w4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33980d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_table.to_excel('stimuli_list.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5b6eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_table2 = pd.DataFrame(df['sentence'].apply(lambda x:x.split()))\n",
    "exp_table2['sent_id'] = df['sentence_id']\n",
    "exp_table2['target'] = df['target']\n",
    "exp_table2.to_excel('stimuli_list2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e6c2426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence_id', 'sentence', 'congruent', 'target', 'Structure',\n",
       "       'percent', 'position', 'semantics_grammar', 'semantics', 'grammar',\n",
       "       'no', 'unknown', 'most_popular', 'iter', 'length', 'words', 'Subject',\n",
       "       'Verb', 'Object', 'Gen', 'Adj', 'Subject length', 'Subject lemma',\n",
       "       'Verb length', 'Verb lemma', 'Object length', 'Object lemma',\n",
       "       'Gen length', 'Gen lemma', 'Adj length', 'Adj lemma', 'ipm_Subject',\n",
       "       'ipm_Gen', 'ipm_Object', 'ipm_Verb', 'ipm_Adj', 'Subject gender',\n",
       "       'Object gender', 'Gen gender', 'Adj gender', 'task_type',\n",
       "       'target==eval', 'percent>75&evalCorrect',\n",
       "       'percent>75&evalCorrect&normEvalCorrect&SemEvalCorrect',\n",
       "       'percent>75&evalCorrect&normEvalCorrect&GramEvalCorrect',\n",
       "       'percent>75&evalCorrect&normEvalCorrect&SemGramEvalCorrect'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('stimuli_AZh - FINAL.csv')\n",
    "df[['ipm_Subject',\n",
    "       'ipm_Gen', 'ipm_Object', 'ipm_Verb', 'ipm_Adj', ]] = df[['ipm_Subject',\n",
    "       'ipm_Gen', 'ipm_Object', 'ipm_Verb', 'ipm_Adj', ]].map(lambda x: \n",
    "                                                              x.replace(',', '.') if \n",
    "                                                              isinstance(x, str) else x).astype(float)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ff9ab58-c6a0-4c6c-8268-a2dd9998b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[ 'Structure', 'Subject length', 'Subject lemma',\n",
    "       'Verb length', 'Verb lemma', 'Object length', 'Object lemma',\n",
    "       'Gen length', 'Gen lemma', 'Adj length', 'Adj lemma', 'ipm_Subject',\n",
    "       'ipm_Gen', 'ipm_Object', 'ipm_Verb', 'ipm_Adj', ]].groupby('Structure').describe().to_excel('stats.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce4776ed-19ea-4093-b598-19b4f7c3b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('stats.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de1da368-0d9a-45c3-bff5-45f5e5f2f4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence structure</th>\n",
       "      <th>Sentence argument</th>\n",
       "      <th>Mean length, syllables</th>\n",
       "      <th>Mean length, syllables.1</th>\n",
       "      <th>Mean frequency, IPM</th>\n",
       "      <th>SD frequency, IPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>Subject</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>162.41</td>\n",
       "      <td>424.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>Subject</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.98</td>\n",
       "      <td>102.75</td>\n",
       "      <td>135.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>Subject</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.27</td>\n",
       "      <td>117.35</td>\n",
       "      <td>185.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>Verb</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.97</td>\n",
       "      <td>154.37</td>\n",
       "      <td>179.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>Verb</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.94</td>\n",
       "      <td>113.02</td>\n",
       "      <td>158.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>Verb</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>123.96</td>\n",
       "      <td>200.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>Object</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.39</td>\n",
       "      <td>94.79</td>\n",
       "      <td>86.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>Object</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.19</td>\n",
       "      <td>120.05</td>\n",
       "      <td>167.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>Object</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.31</td>\n",
       "      <td>129.81</td>\n",
       "      <td>207.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>Genitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>Genitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>Genitive</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.38</td>\n",
       "      <td>137.51</td>\n",
       "      <td>248.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Subject - Verb - Adj - Object</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>141.28</td>\n",
       "      <td>274.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Subject - Verb - Object</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Subject - Verb - Object - Gen</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence structure Sentence argument  Mean length, syllables  \\\n",
       "0   Subject - Verb - Adj - Object           Subject                    3.20   \n",
       "1         Subject - Verb - Object           Subject                    3.18   \n",
       "2   Subject - Verb - Object - Gen           Subject                    3.60   \n",
       "3   Subject - Verb - Adj - Object              Verb                    3.50   \n",
       "4         Subject - Verb - Object              Verb                    3.64   \n",
       "5   Subject - Verb - Object - Gen              Verb                    3.76   \n",
       "6   Subject - Verb - Adj - Object            Object                    3.26   \n",
       "7         Subject - Verb - Object            Object                    3.30   \n",
       "8   Subject - Verb - Object - Gen            Object                    3.32   \n",
       "9   Subject - Verb - Adj - Object          Genitive                     NaN   \n",
       "10        Subject - Verb - Object          Genitive                     NaN   \n",
       "11  Subject - Verb - Object - Gen          Genitive                    3.78   \n",
       "12  Subject - Verb - Adj - Object         Adjective                    4.00   \n",
       "13        Subject - Verb - Object         Adjective                     NaN   \n",
       "14  Subject - Verb - Object - Gen         Adjective                     NaN   \n",
       "\n",
       "    Mean length, syllables.1  Mean frequency, IPM  SD frequency, IPM  \n",
       "0                       1.00               162.41             424.47  \n",
       "1                       0.98               102.75             135.10  \n",
       "2                       1.27               117.35             185.70  \n",
       "3                       0.97               154.37             179.53  \n",
       "4                       0.94               113.02             158.14  \n",
       "5                       0.89               123.96             200.20  \n",
       "6                       1.39                94.79              86.98  \n",
       "7                       1.19               120.05             167.27  \n",
       "8                       1.31               129.81             207.81  \n",
       "9                        NaN                 0.02               0.00  \n",
       "10                       NaN                 0.02               0.00  \n",
       "11                      1.38               137.51             248.08  \n",
       "12                      1.13               141.28             274.98  \n",
       "13                       NaN                 0.02               0.00  \n",
       "14                       NaN                 0.02               0.00  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6db3f764-f98b-4c69-af06-fbfb69960b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for _, row in df.round(2).iterrows():\n",
    "    text.append(' & '.join(row.values.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "763a5b10-a7ab-4b85-bc16-ca2e5093df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject - Verb - Adj - Object & Subject & 3.2 & 1.0 & 162.41 & 424.47 \\\\\n",
      "Subject - Verb - Object & Subject & 3.18 & 0.98 & 102.75 & 135.1 \\\\\n",
      "Subject - Verb - Object - Gen & Subject & 3.6 & 1.27 & 117.35 & 185.7 \\\\\n",
      "Subject - Verb - Adj - Object & Verb & 3.5 & 0.97 & 154.37 & 179.53 \\\\\n",
      "Subject - Verb - Object & Verb & 3.64 & 0.94 & 113.02 & 158.14 \\\\\n",
      "Subject - Verb - Object - Gen & Verb & 3.76 & 0.89 & 123.96 & 200.2 \\\\\n",
      "Subject - Verb - Adj - Object & Object & 3.26 & 1.39 & 94.79 & 86.98 \\\\\n",
      "Subject - Verb - Object & Object & 3.3 & 1.19 & 120.05 & 167.27 \\\\\n",
      "Subject - Verb - Object - Gen & Object & 3.32 & 1.31 & 129.81 & 207.81 \\\\\n",
      "Subject - Verb - Adj - Object & Genitive & nan & nan & 0.02 & 0.0 \\\\\n",
      "Subject - Verb - Object & Genitive & nan & nan & 0.02 & 0.0 \\\\\n",
      "Subject - Verb - Object - Gen & Genitive & 3.78 & 1.38 & 137.51 & 248.08 \\\\\n",
      "Subject - Verb - Adj - Object & Adjective & 4.0 & 1.13 & 141.28 & 274.98 \\\\\n",
      "Subject - Verb - Object & Adjective & nan & nan & 0.02 & 0.0 \\\\\n",
      "Subject - Verb - Object - Gen & Adjective & nan & nan & 0.02 & 0.0\n"
     ]
    }
   ],
   "source": [
    "print(' \\\\\\\\\\n'.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e9041-45fd-4fe2-9d15-858c6c4570d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
